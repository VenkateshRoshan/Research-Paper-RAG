{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infering on deployed RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Prediction Results ===\n",
      "\n",
      "Query: What is the Transformer model?\n",
      "\n",
      "Response: The transformer is a neural network component that can be used to learn useful representations of sequences or sets of data-points. The transformer has driven recent advances in natural language processing, computer vision, and spatio-temporal modelling.\n",
      "\n",
      "References:\n",
      "\n",
      "[1] Title: An Introduction to Transformers\n",
      "    Authors: Richard E. Turner\n",
      "    Categories: cs.LG cs.AI\n",
      "    Relevance Score: 0.52\n",
      "    Citation: Richard E. Turner. \"An Introduction to Transformers\". cs.LG cs.AI.\n",
      "\n",
      "\n",
      "[2] Title: A Survey of Techniques for Optimizing Transformer Inference\n",
      "    Authors: Krishna Teja Chitty-Venkata, Sparsh Mittal, Murali Emani, Venkatram\n",
      "  Vishwanath, Arun K. Somani\n",
      "    Categories: cs.LG cs.AR cs.CL cs.CV\n",
      "    Relevance Score: 0.48\n",
      "    Citation: Krishna Teja Chitty-Venkata, Sparsh Mittal, Murali Emani, Venkatram\n",
      "  Vishwanath, Arun K. Somani. \"A Survey of Techniques for Optimizing Transformer Inference\". cs.LG cs.AR cs.CL cs.CV.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "from google.auth import credentials, load_credentials_from_dict\n",
    "import json\n",
    "from google.protobuf.json_format import MessageToDict\n",
    "from datetime import datetime\n",
    "\n",
    "# Load credentials and initialize client\n",
    "credentials, project_id = load_credentials_from_dict(\n",
    "    json.load(open('research-paper-rag-0a8819b735b9.json'))\n",
    ")\n",
    "\n",
    "client_options = {\"api_endpoint\": \"us-central1-aiplatform.googleapis.com\"}\n",
    "client = aiplatform.gapic.PredictionServiceClient(\n",
    "    client_options=client_options,\n",
    "    credentials=credentials\n",
    ")\n",
    "\n",
    "# Endpoint configuration\n",
    "project = \"research-paper-rag\"\n",
    "location = \"us-central1\"\n",
    "endpoint_id = \"3729166308927864832\"\n",
    "endpoint = f\"projects/{project}/locations/{location}/endpoints/{endpoint_id}\"\n",
    "\n",
    "def format_references(references):\n",
    "    \"\"\"Format references into a readable string\"\"\"\n",
    "    formatted_text = \"\"\n",
    "    for i, ref in enumerate(references, 1):\n",
    "        ref_dict = dict(ref)\n",
    "        formatted_text += f\"\\n[{i}] Title: {ref_dict.get('title', '')}\\n\"\n",
    "        formatted_text += f\"    Authors: {', '.join(ref_dict.get('authors', []))}\\n\"\n",
    "        formatted_text += f\"    Categories: {ref_dict.get('categories', '')}\\n\"\n",
    "        formatted_text += f\"    Relevance Score: {ref_dict.get('relevance_score', 0.0):.2f}\\n\"\n",
    "        formatted_text += f\"    Citation: {ref_dict.get('citation', '')}\\n\\n\"\n",
    "    return formatted_text\n",
    "\n",
    "def predict_query(query, max_tokens):\n",
    "    try:\n",
    "        # Prepare input data\n",
    "        input_data = {\n",
    "            \"instances\": [{\n",
    "                \"query\": query,\n",
    "                'max_tokens': max_tokens,\n",
    "                'num_papers': 2\n",
    "            }]\n",
    "        }\n",
    "        \n",
    "        # Get prediction\n",
    "        response = client.predict(endpoint=endpoint, instances=input_data[\"instances\"])\n",
    "        prediction = dict(response.predictions[0])\n",
    "        \n",
    "        # Format response\n",
    "        main_response = prediction['response']\n",
    "        references = format_references(prediction['references'])\n",
    "        \n",
    "        return main_response, references\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\", \"Error retrieving references\"\n",
    "    \n",
    "Query = \"What is the Transformer model?\"\n",
    "max_tokens = 300\n",
    "response, references = predict_query(Query, max_tokens)\n",
    "\n",
    "print(\"\\n=== Prediction Results ===\\n\")\n",
    "print(f\"Query: {Query}\\n\")\n",
    "print(f\"Response: {response}\\n\")\n",
    "print(\"References:\")\n",
    "print(references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infering on Original Model and Comparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abven/Documents/Projects/Research-Paper-RAG/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'a samurai'}]\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\")\n",
    "\n",
    "# inference\n",
    "output = pipe(\"what is Transformer model?\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
